# Pipeline ETL: AutomatizaciÃ³n de Datos

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline de ETL (ExtracciÃ³n, TransformaciÃ³n y Carga) completamente automatizado, diseÃ±ado para facilitar la integraciÃ³n de datos desde mÃºltiples fuentes de manera eficiente y precisa. Este pipeline permite preparar y mover datos para su anÃ¡lisis en bases de datos, garantizando flexibilidad y escalabilidad en el manejo de la informaciÃ³n.

El diseÃ±o modular del proyecto permite agregar nuevos casos de extracciÃ³n y carga segÃºn las necesidades, lo que lo hace fÃ¡cilmente adaptable a diferentes fuentes de datos y bases de datos de destino.

A continuaciÃ³n, se detallan las etapas del proceso ETL:

1. **Extraction**: Captura y lee datos desde diversas fuentes, como archivos CSV, APIs y bases de datos externas.
2. **Transform**: Realiza limpieza, formateo y enriquecimiento de datos, asegurando que estÃ©n listos para anÃ¡lisis o almacenamiento.
3. **Load**: Inserta los datos transformados en una base de datos de destino (por ejemplo, PostgreSQL o MySQL) para facilitar consultas y anÃ¡lisis.

## ğŸ§‘â€ğŸ’» Estructura del Proyecto de ETL

```plaintext
etl_automation/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ db_config.yaml        # Archivo de configuraciÃ³n para almacenar credenciales y detalles de conexiÃ³n a las bases de datos (PostgreSQL, MySQL).
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_data.csv       # Datos de ejemplo en formato .csv para la prueba de la automatizaciÃ³n.
â”‚
â”œâ”€â”€ etl_pipeline.py           # CÃ³digo principal de Python que realiza las funciones de ExtracciÃ³n, TransformaciÃ³n y Carga.
â”œâ”€â”€ README.md                 # Archivo de documentaciÃ³n que explica el proyecto y su uso.
â””â”€â”€ requirements.txt          # LibrerÃ­as necesarias para ejecutar el pipeline de ETL.
```

## ğŸ› ï¸ Herramientas y LibrerÃ­as

- **Python**: Para scripting.
- **SQLAlchemy**: Conexiones a bases de datos.
- **Pandas**: ManipulaciÃ³n de datos.
- **PyYAML**: Lectura de configuraciones.

## âš™ï¸ ConfiguraciÃ³n

1. Clona el repositorio:

   ```plaintext
   git clone https://github.com/tu_usuario/etl_automation.git
   ```

2. Instala las dependencias:

   ```plaintext
   pip install -r requirements.txt
   ```

3. Configura las credenciales en config/db_config.yaml.

## âŒ› EjecuciÃ³n

- Ejecuta el pipeline de ETL:

  ```bash
  python etl_pipeline.py
  ```

## ğŸ«‚ Contribuciones

> **ğŸ’¡ SiÃ©ntete libre de contribuir a este repositorio o utilizarlo como base para tus propios proyectos de ETL. Â¡Tu aporte y creatividad son bienvenidos!**

<!-- Connect With Me -->

## âœ‰ï¸ Contacto

<a href="https://www.linkedin.com/in/jeanpaulomv/"><img src="https://img.shields.io/badge/jeanpaulomv-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn" height="30"></a>
<a href="https://www.datascienceportfol.io/jeanpaulomv"><img src="https://img.shields.io/badge/Portfolio-255E63?style=for-the-badge&logo=About.me&logoColor=white" alt="Portfolio" height="30"></a>
